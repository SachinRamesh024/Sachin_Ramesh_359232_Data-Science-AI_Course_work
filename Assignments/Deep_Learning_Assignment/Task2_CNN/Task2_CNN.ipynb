{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63fb8d44-8b95-410d-9a30-7a5b2afef96c",
   "metadata": {},
   "source": [
    "# Task 2: Convolutional Neural Network (CNN)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "55357540-3eb2-4214-90c9-d807b9ba215d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Import libraries\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "306f0a0a-105c-4766-93a2-066530e53153",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Load Dataset\n",
    "(train_images, train_labels), (test_images, test_labels) = datasets.fashion_mnist.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "718c0e50-40f7-4f07-b5e0-6681b405802b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We reduce the dataset size to save memory and time.\n",
    "# We will use 10,000 images for training and 2,000 for testing.\n",
    "train_images = train_images[:10000]\n",
    "train_labels = train_labels[:10000]\n",
    "test_images = test_images[:2000]  # Increased test set for better evaluation\n",
    "test_labels = test_labels[:2000]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc53cb69-6bed-4fe2-b8da-1a8f893dc57d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalization and Reshaping\n",
    "train_images = train_images / 255.0\n",
    "test_images = test_images / 255.0\n",
    "train_images = train_images.reshape((-1, 28, 28, 1))\n",
    "test_images = test_images.reshape((-1, 28, 28, 1))\n",
    "\n",
    "class_names = ['T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',\n",
    "               'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53854223-0c34-431e-8c65-4977487f2ae8",
   "metadata": {},
   "source": [
    "# DESIGN CNN ARCHITECTURE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "156148ac-9985-403c-a036-2a00f1e2155f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\sachi\\Downloads\\Annaconda\\envs\\tf\\lib\\site-packages\\keras\\src\\layers\\convolutional\\base_conv.py:113: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
      "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "\n",
    "# Block 1\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 2 \n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "\n",
    "# Block 3 \n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "\n",
    "# Fully Connected Layers with Dropout\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "model.add(layers.Dropout(0.3))\n",
    "model.add(layers.Dense(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867eb404-0646-49d8-bb50-583def6a534f",
   "metadata": {},
   "source": [
    "# Compile Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "11019856-c87b-4607-913c-ccb2fce0d207",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam',\n",
    "              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc2f79e1-b8f5-4998-8e19-7555781cd5d0",
   "metadata": {},
   "source": [
    "# Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "262a1a64-788e-4afd-afdd-f9f9bfdde14b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 41ms/step - accuracy: 0.6340 - loss: 0.9826 - val_accuracy: 0.7670 - val_loss: 0.6068\n",
      "Epoch 2/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 41ms/step - accuracy: 0.7738 - loss: 0.6012 - val_accuracy: 0.8155 - val_loss: 0.5034\n",
      "Epoch 3/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 40ms/step - accuracy: 0.8080 - loss: 0.5184 - val_accuracy: 0.8385 - val_loss: 0.4706\n",
      "Epoch 4/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 51ms/step - accuracy: 0.8324 - loss: 0.4587 - val_accuracy: 0.8535 - val_loss: 0.4109\n",
      "Epoch 5/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 38ms/step - accuracy: 0.8474 - loss: 0.4220 - val_accuracy: 0.8520 - val_loss: 0.3961\n",
      "Epoch 6/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - accuracy: 0.8598 - loss: 0.3830 - val_accuracy: 0.8600 - val_loss: 0.3797\n",
      "Epoch 7/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - accuracy: 0.8709 - loss: 0.3515 - val_accuracy: 0.8745 - val_loss: 0.3587\n",
      "Epoch 8/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - accuracy: 0.8775 - loss: 0.3327 - val_accuracy: 0.8710 - val_loss: 0.3537\n",
      "Epoch 9/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - accuracy: 0.8880 - loss: 0.3064 - val_accuracy: 0.8750 - val_loss: 0.3532\n",
      "Epoch 10/10\n",
      "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 37ms/step - accuracy: 0.8893 - loss: 0.2926 - val_accuracy: 0.8695 - val_loss: 0.3714\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(train_images, train_labels, epochs=10, \n",
    "                    validation_data=(test_images, test_labels), verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "571b809e-0d12-4222-b5a4-0aa8b4a06858",
   "metadata": {},
   "source": [
    "# Evaluate Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df3e26e2-1488-4c24-ba6d-f712c9e7053d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Final Evaluation ---\n",
      "\u001b[1m63/63\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n--- Final Evaluation ---\")\n",
    "y_pred_probs = model.predict(test_images)\n",
    "y_pred_classes = np.argmax(y_pred_probs, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ea236b09-b548-44bb-b2f2-54b852a96e63",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification Report:\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " T-shirt/top       0.88      0.81      0.84       200\n",
      "     Trouser       0.99      0.96      0.97       203\n",
      "    Pullover       0.82      0.86      0.84       214\n",
      "       Dress       0.89      0.87      0.88       190\n",
      "        Coat       0.87      0.62      0.72       219\n",
      "      Sandal       0.99      0.95      0.97       195\n",
      "       Shirt       0.55      0.80      0.65       197\n",
      "     Sneaker       0.94      0.95      0.95       200\n",
      "         Bag       0.98      0.95      0.97       194\n",
      "  Ankle boot       0.94      0.97      0.95       188\n",
      "\n",
      "    accuracy                           0.87      2000\n",
      "   macro avg       0.89      0.87      0.87      2000\n",
      "weighted avg       0.88      0.87      0.87      2000\n",
      "\n"
     ]
    }
   ],
   "source": [
    "report = classification_report(test_labels, y_pred_classes, target_names=class_names)\n",
    "print(\"\\nClassification Report:\\n\")\n",
    "print(report)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a479046-f5b7-423d-9f72-484a3622d4af",
   "metadata": {},
   "source": [
    "# Metric Explanations\n",
    "\n",
    "## 1. Accuracy\n",
    "The percentage of images correctly classified (e.g., how many T-shirts were actually labeled T-shirts).\n",
    "\n",
    "## 2. Precision\n",
    "Accuracy of positive predictions. Low precision for 'Sneaker' means the model is confusing other shoes with Sneakers.\n",
    "\n",
    "## 3. Recall\n",
    "Ability to find all samples of a class. Low recall for 'Bag' means the model is missing a lot of Bags.\n",
    "\n",
    "## 4. F1-Score\n",
    "The balance between Precision and Recall. Good for understanding overall class performance.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d888d723-59a9-44e1-8a3f-beb0a6d04911",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (TensorFlow)",
   "language": "python",
   "name": "tf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
